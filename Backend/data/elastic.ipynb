{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "import sys\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party imports\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import your models (assuming they're in a models.py file)\n",
    "from models import Recipe, RecipeAdd, User, Feedback, Review, UserReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Elasticsearch\n",
      "{'name': 'e580306f495c', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'dpNy2-X0Qn2KylAhc84n0A', 'version': {'number': '8.17.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '2b6a7fed44faa321997703718f07ee0420804b41', 'build_date': '2024-12-11T12:08:05.663969764Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Create Elasticsearch client\n",
    "es = Elasticsearch(\n",
    "    \"http://localhost:9200\",  # Changed from https to http\n",
    "    basic_auth=(\"elastic\", \"pass\"),  # Use your actual password\n",
    ")\n",
    "# Update disk watermark thresholds\n",
    "es.cluster.put_settings(\n",
    "    body={\n",
    "        \"persistent\": {\n",
    "            \"cluster.routing.allocation.disk.watermark.low\": \"99%\",\n",
    "            \"cluster.routing.allocation.disk.watermark.high\": \"99%\",\n",
    "            \"cluster.routing.allocation.disk.watermark.flood_stage\": \"99%\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "# Test connection\n",
    "try:\n",
    "    if es.ping():\n",
    "        print(\"Successfully connected to Elasticsearch\")\n",
    "        print(es.info())\n",
    "    else:\n",
    "        print(\"Could not connect to Elasticsearch\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch mappings for the models\n",
    "\n",
    "USER_MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"email\": {\"type\": \"keyword\"},\n",
    "            \"name\": {\"type\": \"text\"},\n",
    "            \"password\": {\"type\": \"keyword\"},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,  # Adjust dimension based on your embedding size\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "RECIPE_MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"integer\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"ingredients\": {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\"}}},\n",
    "            \"instructions\": {\"type\": \"text\"},\n",
    "            \"prep_time\": {\"type\": \"integer\"},\n",
    "            \"cook_time\": {\"type\": \"integer\"},\n",
    "            \"cuisine\": {\"type\": \"keyword\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"diet\": {\"type\": \"keyword\"},\n",
    "            \"image\": {\"type\": \"keyword\", \"index\": False},\n",
    "            \"url\": {\"type\": \"keyword\", \"index\": False},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,  # Adjust dimension based on your embedding size\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "FEEDBACK_MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"email\": {\"type\": \"keyword\"},\n",
    "            \"input_description\": {\"type\": \"text\"},\n",
    "            \"input_image\": {\"type\": \"text\", \"index\": False},\n",
    "            \"recipe_ids\": {\"type\": \"integer\"},\n",
    "            \"rating\": {\"type\": \"integer\"},\n",
    "            \"comment\": {\"type\": \"text\"},\n",
    "            \"created_at\": {\"type\": \"date\"},  # Added creation date\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "USER_REVIEW_MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"email\": {\"type\": \"keyword\"},\n",
    "            \"reviews\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"content\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },  # Changed from \"text\" to match the model\n",
    "                    \"created_at\": {\"type\": \"date\"},  # Added creation date\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "RECIPE_ADD_MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"integer\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"ingredients\": {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\"}}},\n",
    "            \"instructions\": {\"type\": \"text\"},\n",
    "            \"prep_time\": {\"type\": \"integer\"},\n",
    "            \"cook_time\": {\"type\": \"integer\"},\n",
    "            \"cuisine\": {\"type\": \"keyword\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"diet\": {\"type\": \"keyword\"},\n",
    "            \"image\": {\"type\": \"keyword\", \"index\": False},\n",
    "            \"url\": {\"type\": \"keyword\", \"index\": False},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,  # Adjust dimension based on your embedding size\n",
    "            },\n",
    "            \"accepted\": {\"type\": \"boolean\"},\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index 'users'...\n",
      "Successfully created index 'users'\n",
      "Creating index 'recipes'...\n",
      "Successfully created index 'recipes'\n",
      "Creating index 'feedback'...\n",
      "Successfully created index 'feedback'\n",
      "Creating index 'user_reviews'...\n",
      "Successfully created index 'user_reviews'\n",
      "Creating index 'recipe_additions'...\n",
      "Successfully created index 'recipe_additions'\n"
     ]
    }
   ],
   "source": [
    "# ... existing elasticsearch import and client setup ...\n",
    "def create_indices(es_client):\n",
    "    \"\"\"Create all required indices if they don't exist\"\"\"\n",
    "    for index_name, mapping in MAPPINGS.items():\n",
    "        try:\n",
    "            if not es_client.indices.exists(index=index_name):\n",
    "                print(f\"Creating index '{index_name}'...\")\n",
    "                es_client.indices.create(index=index_name, body=mapping)\n",
    "                print(f\"Successfully created index '{index_name}'\")\n",
    "            else:\n",
    "                print(f\"Index '{index_name}' already exists\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating index '{index_name}': {e}\")\n",
    "\n",
    "\n",
    "# Define the mapping dictionary\n",
    "MAPPINGS = {\n",
    "    \"users\": USER_MAPPING,\n",
    "    \"recipes\": RECIPE_MAPPING,\n",
    "    \"feedback\": FEEDBACK_MAPPING,\n",
    "    \"user_reviews\": USER_REVIEW_MAPPING,\n",
    "    \"recipe_additions\": RECIPE_ADD_MAPPING,\n",
    "}\n",
    "\n",
    "# Create all indices\n",
    "create_indices(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index 'users'...\n",
      "Successfully deleted index 'users'\n",
      "Deleting index 'recipes'...\n",
      "Successfully deleted index 'recipes'\n",
      "Deleting index 'feedback'...\n",
      "Successfully deleted index 'feedback'\n",
      "Deleting index 'user_reviews'...\n",
      "Successfully deleted index 'user_reviews'\n",
      "Deleting index 'recipe_additions'...\n",
      "Successfully deleted index 'recipe_additions'\n"
     ]
    }
   ],
   "source": [
    "def delete_indices(es_client):\n",
    "    \"\"\"Delete all indices defined in MAPPINGS\"\"\"\n",
    "    for index_name in MAPPINGS.keys():\n",
    "        try:\n",
    "            if es_client.indices.exists(index=index_name):\n",
    "                print(f\"Deleting index '{index_name}'...\")\n",
    "                es_client.indices.delete(index=index_name)\n",
    "                print(f\"Successfully deleted index '{index_name}'\")\n",
    "            else:\n",
    "                print(f\"Index '{index_name}' does not exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting index '{index_name}': {e}\")\n",
    "\n",
    "\n",
    "# Delete all indices\n",
    "# delete_indices(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'recipes' contains 5044 documents\n"
     ]
    }
   ],
   "source": [
    "def check_index_stats(es_client, index_name=\"recipes\"):\n",
    "    \"\"\"\n",
    "    Check if an index exists and get its document count\n",
    "\n",
    "    Args:\n",
    "        es_client: AsyncElasticsearch client\n",
    "        index_name: Name of the index to check\n",
    "\n",
    "    Returns:\n",
    "        bool: True if index exists and has documents, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if index exists\n",
    "        if not es_client.indices.exists(index=index_name):\n",
    "            print(f\"Index '{index_name}' does not exist!\")\n",
    "            return False\n",
    "\n",
    "        # Get document count\n",
    "        stats = es_client.count(index=index_name)\n",
    "        doc_count = stats[\"count\"]\n",
    "\n",
    "        print(f\"Index '{index_name}' contains {doc_count} documents\")\n",
    "        return doc_count > 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking index: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "has_documents = check_index_stats(es)\n",
    "if not has_documents:\n",
    "    print(\"Index is empty! You may need to index some documents first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data and index it to elastic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>course</th>\n",
       "      <th>diet</th>\n",
       "      <th>image</th>\n",
       "      <th>url</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4529</td>\n",
       "      <td>lavand-e-murgh recipe - afghani chicken in yog...</td>\n",
       "      <td>['fresh pomegranate fruit kernels few garnish'...</td>\n",
       "      <td>['to begin making the lavand-e-murgh recipe, w...</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>Afghan</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>High Protein Non Vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.archanaskitchen.com/lavand-e-murgh...</td>\n",
       "      <td>[[-0.0026710997335612774, 0.003612738568335771...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4640</td>\n",
       "      <td>afghani dhoog recipe - cucumber mint buttermil...</td>\n",
       "      <td>['cumin powder jeera', 'curd dahi yogurt', 'sa...</td>\n",
       "      <td>['to begin making the afghani dhoog recipe - c...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghan</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.archanaskitchen.com/doogh-afghani-y...</td>\n",
       "      <td>[[-0.014779524877667427, -0.008534302935004234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5978</td>\n",
       "      <td>malida recipe (healthy whole wheat afghan sweet)</td>\n",
       "      <td>['cardamom powder elaichi', 'dates pitted fine...</td>\n",
       "      <td>['to begin making the malida recipe, tear the ...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Afghan</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.archanaskitchen.com/malida-recipe-...</td>\n",
       "      <td>[[-0.01772255077958107, -0.019701037555933, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7092</td>\n",
       "      <td>moroccan spiced millet and lentil salad recipe</td>\n",
       "      <td>['tomato chopped', 'extra virgin olive oil', '...</td>\n",
       "      <td>['to begin making the moroccan spiced millet a...</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>African</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.archanaskitchen.com/moroccan-spice...</td>\n",
       "      <td>[[-0.06342744827270508, -0.01326711568981409, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6684</td>\n",
       "      <td>chickpea &amp; date tagine recipe</td>\n",
       "      <td>['onion', 'cumin powder jeera', 'extra virgin ...</td>\n",
       "      <td>['to begin making the chickpea &amp; date tagine r...</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>African</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.archanaskitchen.com/chickpea-date-...</td>\n",
       "      <td>[[-0.03216571733355522, 0.029672250151634216, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title  \\\n",
       "0  4529  lavand-e-murgh recipe - afghani chicken in yog...   \n",
       "1  4640  afghani dhoog recipe - cucumber mint buttermil...   \n",
       "2  5978   malida recipe (healthy whole wheat afghan sweet)   \n",
       "3  7092     moroccan spiced millet and lentil salad recipe   \n",
       "4  6684                      chickpea & date tagine recipe   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ['fresh pomegranate fruit kernels few garnish'...   \n",
       "1  ['cumin powder jeera', 'curd dahi yogurt', 'sa...   \n",
       "2  ['cardamom powder elaichi', 'dates pitted fine...   \n",
       "3  ['tomato chopped', 'extra virgin olive oil', '...   \n",
       "4  ['onion', 'cumin powder jeera', 'extra virgin ...   \n",
       "\n",
       "                                        instructions  prep_time  cook_time  \\\n",
       "0  ['to begin making the lavand-e-murgh recipe, w...         15         25   \n",
       "1  ['to begin making the afghani dhoog recipe - c...         10          0   \n",
       "2  ['to begin making the malida recipe, tear the ...         20         20   \n",
       "3  ['to begin making the moroccan spiced millet a...         10         20   \n",
       "4  ['to begin making the chickpea & date tagine r...         15         60   \n",
       "\n",
       "   cuisine  course                         diet  image  \\\n",
       "0   Afghan  Dinner  High Protein Non Vegetarian    NaN   \n",
       "1   Afghan   Snack                   Vegetarian    NaN   \n",
       "2   Afghan   Snack                   Vegetarian    NaN   \n",
       "3  African  Dinner                   Vegetarian    NaN   \n",
       "4  African  Dinner      High Protein Vegetarian    NaN   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.archanaskitchen.com/lavand-e-murgh...   \n",
       "1  http://www.archanaskitchen.com/doogh-afghani-y...   \n",
       "2  https://www.archanaskitchen.com/malida-recipe-...   \n",
       "3  https://www.archanaskitchen.com/moroccan-spice...   \n",
       "4  https://www.archanaskitchen.com/chickpea-date-...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[-0.0026710997335612774, 0.003612738568335771...  \n",
       "1  [[-0.014779524877667427, -0.008534302935004234...  \n",
       "2  [[-0.01772255077958107, -0.019701037555933, -0...  \n",
       "3  [[-0.06342744827270508, -0.01326711568981409, ...  \n",
       "4  [[-0.03216571733355522, 0.029672250151634216, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Add import at the top\n",
    "import ast\n",
    "\n",
    "# Convert string representation to actual array when reading the embedding\n",
    "df[\"embedding\"] = df[\"embedding\"].apply(ast.literal_eval)\n",
    "\n",
    "# Now when you check the embedding, it will be an actual array\n",
    "print(type(df[\"embedding\"].loc[0]))  # Should print: <class 'list'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index one document through recipe model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from typing import Dict, Any\n",
    "import sys\n",
    "from models import Recipe, Feedback\n",
    "\n",
    "# ... existing code ...\n",
    "\n",
    "\n",
    "def index_recipe_to_elastic(\n",
    "    recipe: Recipe, es_client: Elasticsearch, index_name: str = \"recipes\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Index a recipe to Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        recipe: Recipe model instance\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index (default: \"recipes\")\n",
    "    \"\"\"\n",
    "    doc = {\n",
    "        \"id\": recipe.id,\n",
    "        \"title\": recipe.title,\n",
    "        \"ingredients\": recipe.ingredients,\n",
    "        \"instructions\": recipe.instructions,\n",
    "        \"prep_time\": recipe.prep_time,\n",
    "        \"cook_time\": recipe.cook_time,\n",
    "        \"cuisine\": recipe.cuisine,\n",
    "        \"course\": recipe.course,\n",
    "        \"diet\": recipe.diet,\n",
    "        \"image\": str(recipe.image) if recipe.image else None,\n",
    "        \"url\": str(recipe.url) if recipe.url else None,\n",
    "        \"embedding\": recipe.embedding,\n",
    "    }\n",
    "\n",
    "    es_client.index(index=index_name, id=str(recipe.id), document=doc)\n",
    "    print(f\"Indexed recipe {recipe.id} to Elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bulk index df recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add necessary imports\n",
    "from models import Recipe, RecipeAdd, User\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add necessary imports\n",
    "from models import Recipe\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def row_to_recipe(row):\n",
    "    \"\"\"Convert a DataFrame row to a Recipe object\"\"\"\n",
    "    # Convert embedding to a flat list of floats\n",
    "    embedding = np.array(row.embedding).flatten().tolist()\n",
    "    try:\n",
    "        return Recipe(\n",
    "            id=row.id,\n",
    "            title=row.title,\n",
    "            ingredients=(\n",
    "                literal_eval(row.ingredients)\n",
    "                if isinstance(row.ingredients, str)\n",
    "                else row.ingredients\n",
    "            ),\n",
    "            instructions=(\n",
    "                literal_eval(row.instructions)\n",
    "                if isinstance(row.instructions, str)\n",
    "                else row.instructions\n",
    "            ),\n",
    "            prep_time=row.prep_time,\n",
    "            cook_time=row.cook_time,\n",
    "            cuisine=row.cuisine,\n",
    "            course=row.course,\n",
    "            diet=row.diet,\n",
    "            image=row.image if pd.notna(row.image) else None,\n",
    "            url=row.url if pd.notna(row.url) else None,\n",
    "            embedding=embedding,  # Now it's a flat list of floats\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5616/1292315588.py:48: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  success, failed = bulk(es_client, actions, chunk_size=500, request_timeout=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 1000 documents\n",
      "Successfully indexed 1000 documents\n",
      "Successfully indexed 1000 documents\n",
      "Successfully indexed 1000 documents\n",
      "Successfully indexed 1000 documents\n",
      "Successfully indexed 44 documents\n"
     ]
    }
   ],
   "source": [
    "def bulk_index_recipe_batch(df_batch, es_client, index_name=\"recipes\"):\n",
    "    \"\"\"\n",
    "    Convert a batch of DataFrame rows to Recipe objects and bulk index them\n",
    "\n",
    "    Args:\n",
    "        df_batch: Pandas DataFrame batch containing recipes\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index\n",
    "    \"\"\"\n",
    "    # Convert rows to Recipe objects and filter out None values\n",
    "    recipes = [\n",
    "        r\n",
    "        for r in (row_to_recipe(row) for _, row in df_batch.iterrows())\n",
    "        if r is not None\n",
    "    ]\n",
    "\n",
    "    if not recipes:\n",
    "        print(\"No valid recipes in this batch\")\n",
    "        return\n",
    "    # Prepare bulk indexing actions\n",
    "    actions = []\n",
    "    for recipe in recipes:\n",
    "        # Build document with required fields\n",
    "        doc = {\n",
    "            \"id\": recipe.id,\n",
    "            \"title\": recipe.title,\n",
    "            \"ingredients\": recipe.ingredients,\n",
    "            \"instructions\": recipe.instructions,\n",
    "            \"prep_time\": recipe.prep_time,\n",
    "            \"cook_time\": recipe.cook_time,\n",
    "            \"cuisine\": recipe.cuisine,\n",
    "            \"course\": recipe.course,\n",
    "            \"diet\": recipe.diet,\n",
    "        }\n",
    "\n",
    "        # Only add optional fields if they're not None\n",
    "        if recipe.image is not None:\n",
    "            doc[\"image\"] = recipe.image\n",
    "        if recipe.url is not None:\n",
    "            doc[\"url\"] = recipe.url\n",
    "        if recipe.embedding is not None:\n",
    "            doc[\"embedding\"] = recipe.embedding\n",
    "\n",
    "        actions.append({\"_index\": index_name, \"_id\": str(recipe.id), \"_source\": doc})\n",
    "\n",
    "    # Perform bulk indexing\n",
    "    try:\n",
    "        success, failed = bulk(es_client, actions, chunk_size=500, request_timeout=30)\n",
    "        print(f\"Successfully indexed {success} documents\")\n",
    "        if failed:\n",
    "            print(f\"Failed to index {len(failed)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during bulk indexing: {e}\")\n",
    "\n",
    "\n",
    "# Usage example - process in batches of 1000\n",
    "batch_size = 1000\n",
    "for start_idx in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[start_idx : start_idx + batch_size]\n",
    "    bulk_index_recipe_batch(batch, es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe Model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Recipe(id=1001, title='Test Recipe', ingredients=['ingredient 1', 'ingredient 2'], instructions=['step 1', 'step 2'], prep_time=15, cook_time=30, cuisine='Italian', course='Main', diet='Vegetarian', image=None, url=None, embedding=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>course</th>\n",
       "      <th>diet</th>\n",
       "      <th>embedding</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Test Recipe</td>\n",
       "      <td>[ingredient 1, ingredient 2]</td>\n",
       "      <td>[step 1, step 2]</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Main</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        title                   ingredients      instructions  \\\n",
       "0  1001  Test Recipe  [ingredient 1, ingredient 2]  [step 1, step 2]   \n",
       "\n",
       "   prep_time  cook_time  cuisine course        diet embedding   url  \n",
       "0         15         30  Italian   Main  Vegetarian      None  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_random_recipe(\n",
    "    es_client: Elasticsearch, index_name: str = \"recipes\"\n",
    ") -> tuple[Recipe, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Retrieve a random recipe from Elasticsearch, convert it to a Recipe model and DataFrame\n",
    "\n",
    "    Args:\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Recipe model instance, pandas DataFrame)\n",
    "    \"\"\"\n",
    "    # Random query\n",
    "    random_query = {\n",
    "        \"query\": {\"function_score\": {\"query\": {\"match_all\": {}}, \"random_score\": {}}},\n",
    "        \"size\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Execute search\n",
    "        result = es_client.search(index=index_name, body=random_query)\n",
    "\n",
    "        if not result[\"hits\"][\"hits\"]:\n",
    "            raise ValueError(\"No documents found in the index\")\n",
    "\n",
    "        # Convert to Recipe model\n",
    "        hit = result[\"hits\"][\"hits\"][0][\"_source\"]\n",
    "        recipe = Recipe(\n",
    "            id=hit[\"id\"],\n",
    "            title=hit[\"title\"],\n",
    "            ingredients=hit[\"ingredients\"],\n",
    "            instructions=hit[\"instructions\"],\n",
    "            prep_time=hit[\"prep_time\"],\n",
    "            cook_time=hit[\"cook_time\"],\n",
    "            cuisine=hit[\"cuisine\"],\n",
    "            course=hit[\"course\"],\n",
    "            diet=hit[\"diet\"],\n",
    "            image=hit.get(\"image\"),\n",
    "            url=hit.get(\"url\"),\n",
    "            embedding=hit.get(\"embedding\"),\n",
    "        )\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        recipe_df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"id\": recipe.id,\n",
    "                    \"title\": recipe.title,\n",
    "                    \"ingredients\": recipe.ingredients,\n",
    "                    \"instructions\": recipe.instructions,\n",
    "                    \"prep_time\": recipe.prep_time,\n",
    "                    \"cook_time\": recipe.cook_time,\n",
    "                    \"cuisine\": recipe.cuisine,\n",
    "                    \"course\": recipe.course,\n",
    "                    \"diet\": recipe.diet,\n",
    "                    \"embedding\": recipe.embedding,\n",
    "                    \"url\": recipe.url,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return recipe, recipe_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving random recipe: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "recipe, df = get_random_recipe(es)\n",
    "if recipe:\n",
    "    print(\"Recipe Model:\")\n",
    "    display(recipe)\n",
    "    print(\"\\nDataFrame:\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe Model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecipeAdd(id=2001, title='Homemade Pizza', ingredients=['2 cups all-purpose flour', '1 cup warm water', '2 tbsp olive oil', '1 tsp yeast', '1 tsp salt', 'Pizza toppings of choice'], instructions=['Mix flour, water, oil, yeast, and salt', 'Knead dough for 10 minutes', 'Let rise for 1 hour', 'Roll out and add toppings', 'Bake at 450°F for 15 minutes'], prep_time=70, cook_time=15, cuisine='Italian', course='Main Dish', diet='Vegetarian', image='https://example.com/pizza.jpg', url='https://example.com/homemade-pizza', embedding=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], accepted=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>course</th>\n",
       "      <th>diet</th>\n",
       "      <th>embedding</th>\n",
       "      <th>url</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>Homemade Pizza</td>\n",
       "      <td>[2 cups all-purpose flour, 1 cup warm water, 2...</td>\n",
       "      <td>[Mix flour, water, oil, yeast, and salt, Knead...</td>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Main Dish</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...</td>\n",
       "      <td>https://example.com/homemade-pizza</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           title                                        ingredients  \\\n",
       "0  2001  Homemade Pizza  [2 cups all-purpose flour, 1 cup warm water, 2...   \n",
       "\n",
       "                                        instructions  prep_time  cook_time  \\\n",
       "0  [Mix flour, water, oil, yeast, and salt, Knead...         70         15   \n",
       "\n",
       "   cuisine     course        diet  \\\n",
       "0  Italian  Main Dish  Vegetarian   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...   \n",
       "\n",
       "                                  url  accepted  \n",
       "0  https://example.com/homemade-pizza     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_random_pending_recipe(\n",
    "    es_client: Elasticsearch, index_name: str = \"recipe_additions\"\n",
    ") -> tuple[RecipeAdd, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Retrieve a random pending recipe from Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index\n",
    "\n",
    "    Returns:\n",
    "        tuple: (RecipeAdd model instance, pandas DataFrame)\n",
    "    \"\"\"\n",
    "    # Random query\n",
    "    random_query = {\n",
    "        \"query\": {\"function_score\": {\"query\": {\"match_all\": {}}, \"random_score\": {}}},\n",
    "        \"size\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Execute search\n",
    "        result = es_client.search(index=index_name, body=random_query)\n",
    "\n",
    "        if not result[\"hits\"][\"hits\"]:\n",
    "            raise ValueError(\"No documents found in the index\")\n",
    "\n",
    "        # Convert to RecipeAdd model\n",
    "        hit = result[\"hits\"][\"hits\"][0][\"_source\"]\n",
    "        recipe = RecipeAdd(\n",
    "            id=hit[\"id\"],\n",
    "            title=hit[\"title\"],\n",
    "            ingredients=hit[\"ingredients\"],\n",
    "            instructions=hit[\"instructions\"],\n",
    "            prep_time=hit[\"prep_time\"],\n",
    "            cook_time=hit[\"cook_time\"],\n",
    "            cuisine=hit[\"cuisine\"],\n",
    "            course=hit[\"course\"],\n",
    "            diet=hit[\"diet\"],\n",
    "            image=hit.get(\"image\"),\n",
    "            url=hit.get(\"url\"),\n",
    "            embedding=hit.get(\"embedding\"),\n",
    "            accepted=hit.get(\"accepted\", False),\n",
    "        )\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        recipe_df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"id\": recipe.id,\n",
    "                    \"title\": recipe.title,\n",
    "                    \"ingredients\": recipe.ingredients,\n",
    "                    \"instructions\": recipe.instructions,\n",
    "                    \"prep_time\": recipe.prep_time,\n",
    "                    \"cook_time\": recipe.cook_time,\n",
    "                    \"cuisine\": recipe.cuisine,\n",
    "                    \"course\": recipe.course,\n",
    "                    \"diet\": recipe.diet,\n",
    "                    \"embedding\": recipe.embedding,\n",
    "                    \"url\": recipe.url,\n",
    "                    \"accepted\": recipe.accepted,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return recipe, recipe_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving random pending recipe: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "recipe, df = get_random_pending_recipe(es)\n",
    "if recipe:\n",
    "    print(\"Recipe Model:\")\n",
    "    display(recipe)\n",
    "    print(\"\\nDataFrame:\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed pending recipe 2001 to recipe_additions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>course</th>\n",
       "      <th>diet</th>\n",
       "      <th>image</th>\n",
       "      <th>url</th>\n",
       "      <th>embedding</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>Homemade Pizza</td>\n",
       "      <td>[2 cups all-purpose flour, 1 cup warm water, 2...</td>\n",
       "      <td>[Mix flour, water, oil, yeast, and salt, Knead...</td>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Main Dish</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>https://example.com/pizza.jpg</td>\n",
       "      <td>https://example.com/homemade-pizza</td>\n",
       "      <td>[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           title                                        ingredients  \\\n",
       "0  2001  Homemade Pizza  [2 cups all-purpose flour, 1 cup warm water, 2...   \n",
       "\n",
       "                                        instructions  prep_time  cook_time  \\\n",
       "0  [Mix flour, water, oil, yeast, and salt, Knead...         70         15   \n",
       "\n",
       "   cuisine     course        diet                          image  \\\n",
       "0  Italian  Main Dish  Vegetarian  https://example.com/pizza.jpg   \n",
       "\n",
       "                                  url  \\\n",
       "0  https://example.com/homemade-pizza   \n",
       "\n",
       "                                           embedding  accepted  \n",
       "0  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def index_pending_recipe(\n",
    "    recipe: Recipe, es_client: Elasticsearch, index_name: str = \"recipe_additions\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Convert Recipe to RecipeAdd and index it to Elasticsearch with accepted=False\n",
    "\n",
    "    Args:\n",
    "        recipe: Recipe model instance\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index for pending recipes\n",
    "    \"\"\"\n",
    "    # Convert to pending RecipeAdd\n",
    "    recipe_dict = recipe.model_dump()\n",
    "    recipe_dict[\"accepted\"] = False\n",
    "\n",
    "    # Create new RecipeAdd instance\n",
    "    pending_recipe = RecipeAdd(**recipe_dict)\n",
    "    # Prepare document\n",
    "    doc = pending_recipe.model_dump()\n",
    "\n",
    "    try:\n",
    "        # Index the document\n",
    "        es_client.index(index=index_name, id=str(recipe.id), document=doc)\n",
    "        print(f\"Successfully indexed pending recipe {recipe.id} to {index_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing pending recipe: {e}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# First, create a sample recipe\n",
    "sample_recipe = Recipe(\n",
    "    id=2001,\n",
    "    title=\"Homemade Pizza\",\n",
    "    ingredients=[\n",
    "        \"2 cups all-purpose flour\",\n",
    "        \"1 cup warm water\",\n",
    "        \"2 tbsp olive oil\",\n",
    "        \"1 tsp yeast\",\n",
    "        \"1 tsp salt\",\n",
    "        \"Pizza toppings of choice\",\n",
    "    ],\n",
    "    instructions=[\n",
    "        \"Mix flour, water, oil, yeast, and salt\",\n",
    "        \"Knead dough for 10 minutes\",\n",
    "        \"Let rise for 1 hour\",\n",
    "        \"Roll out and add toppings\",\n",
    "        \"Bake at 450°F for 15 minutes\",\n",
    "    ],\n",
    "    prep_time=70,\n",
    "    cook_time=15,\n",
    "    cuisine=\"Italian\",\n",
    "    course=\"Main Dish\",\n",
    "    diet=\"Vegetarian\",\n",
    "    image=\"https://example.com/pizza.jpg\",\n",
    "    url=\"https://example.com/homemade-pizza\",\n",
    "    embedding=[0.1] * 768,  # Dummy embedding\n",
    ")\n",
    "\n",
    "# Index the sample recipe\n",
    "index_pending_recipe(sample_recipe, es)\n",
    "\n",
    "# Verify it was indexed\n",
    "result = es.get(index=\"recipe_additions\", id=str(sample_recipe.id))\n",
    "display(pd.DataFrame([result[\"_source\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Results:\n",
      "[{'key': 'Indian', 'doc_count': 942}, {'key': 'Continental', 'doc_count': 805}, {'key': 'North Indian Recipes', 'doc_count': 571}, {'key': 'South Indian Recipes', 'doc_count': 414}, {'key': 'Italian Recipes', 'doc_count': 209}, {'key': 'Bengali Recipes', 'doc_count': 127}, {'key': 'Kerala Recipes', 'doc_count': 115}, {'key': 'Maharashtrian Recipes', 'doc_count': 108}, {'key': 'Fusion', 'doc_count': 106}, {'key': 'Karnataka', 'doc_count': 100}]\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\"unique_categories\": {\"terms\": {\"field\": \"cuisine\"}}},\n",
    "}\n",
    "\n",
    "# Execute the search\n",
    "response = es.search(index=\"recipes\", body=query)\n",
    "\n",
    "# Print the aggregation results\n",
    "print(\"Aggregation Results:\")\n",
    "print(response[\"aggregations\"][\"unique_categories\"][\"buckets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_globals():\n",
    "    \"\"\"Initialize global variables used across the application\"\"\"\n",
    "    global df, distinct_ingredients, cuisines, courses, diets\n",
    "\n",
    "    try:\n",
    "        # Simple aggregation query for all fields\n",
    "        query = {\n",
    "            \"size\": 0,\n",
    "            \"aggs\": {\n",
    "                \"unique_cuisines\": {\"terms\": {\"field\": \"cuisine\", \"size\": 10000}},\n",
    "                \"unique_courses\": {\"terms\": {\"field\": \"course\", \"size\": 10000}},\n",
    "                \"unique_diets\": {\"terms\": {\"field\": \"diet\", \"size\": 10000}},\n",
    "                \"unique_ingredients\": {\n",
    "                    \"terms\": {\"field\": \"ingredients.keyword\", \"size\": 10000}\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Execute the search\n",
    "        response = es.search(index=\"recipes\", body=query)\n",
    "\n",
    "        # Extract values from buckets\n",
    "        cuisines = sorted(\n",
    "            [\n",
    "                bucket[\"key\"]\n",
    "                for bucket in response[\"aggregations\"][\"unique_cuisines\"][\"buckets\"]\n",
    "            ]\n",
    "        )\n",
    "        courses = sorted(\n",
    "            [\n",
    "                bucket[\"key\"]\n",
    "                for bucket in response[\"aggregations\"][\"unique_courses\"][\"buckets\"]\n",
    "            ]\n",
    "        )\n",
    "        diets = sorted(\n",
    "            [\n",
    "                bucket[\"key\"]\n",
    "                for bucket in response[\"aggregations\"][\"unique_diets\"][\"buckets\"]\n",
    "            ]\n",
    "        )\n",
    "        distinct_ingredients = sorted(\n",
    "            [\n",
    "                bucket[\"key\"]\n",
    "                for bucket in response[\"aggregations\"][\"unique_ingredients\"][\"buckets\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Found {len(cuisines)} cuisines, {len(courses)} courses, {len(diets)} diets, \"\n",
    "            f\"and {len(distinct_ingredients)} ingredients\"\n",
    "        )\n",
    "\n",
    "        return distinct_ingredients, cuisines, courses, diets\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing globals from Elasticsearch: {e}\")\n",
    "        return [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 cuisines, 20 courses, 10 diets, and 10000 ingredients\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "distinct_ingredients, cuisines, courses, diets = initialize_globals()\n",
    "print(\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user signup and user loging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed user test@exgample.com to users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>name</th>\n",
       "      <th>password</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test@exgample.com</td>\n",
       "      <td>Test User</td>\n",
       "      <td>hashed_password</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               email       name         password embedding\n",
       "0  test@exgample.com  Test User  hashed_password      None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def index_user(user: User, es_client: Elasticsearch, index_name: str = \"users\") -> bool:\n",
    "    \"\"\"\n",
    "    Index a User model instance into Elasticsearch if it doesn't already exist\n",
    "\n",
    "    Args:\n",
    "        user: User model instance\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index for users (default: \"users\")\n",
    "\n",
    "    Returns:\n",
    "        bool: True if user was indexed successfully, False if user already exists or error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if user already exists\n",
    "        if es_client.exists(index=index_name, id=user.email):\n",
    "            print(f\"User {user.email} already exists in {index_name}\")\n",
    "            return False\n",
    "\n",
    "        # Convert User model to dictionary\n",
    "        doc = user.model_dump()\n",
    "\n",
    "        # Use email as document ID since it's unique\n",
    "        es_client.index(index=index_name, id=user.email, document=doc)\n",
    "        print(f\"Successfully indexed user {user.email} to {index_name}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing user: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "sample_user = User(\n",
    "    email=\"test@exgample.com\",\n",
    "    name=\"Test User\",\n",
    "    password=\"hashed_password\",  # In practice, this should be properly hashed\n",
    ")\n",
    "\n",
    "# Index the sample user\n",
    "index_user(sample_user, es)\n",
    "\n",
    "# Verify it was indexed (optional)\n",
    "result = es.get(index=\"users\", id=sample_user.email)\n",
    "display(pd.DataFrame([result[\"_source\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Login successful: True\n"
     ]
    }
   ],
   "source": [
    "def login_user(\n",
    "    email: str, password: str, es_client: Elasticsearch, index_name: str = \"users\"\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Verify user credentials against Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        email: User's email\n",
    "        password: User's password (should be hashed in production)\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index for users (default: \"users\")\n",
    "\n",
    "    Returns:\n",
    "        bool: True if credentials are valid, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if user exists and get their data\n",
    "        if not es_client.exists(index=index_name, id=email):\n",
    "            print(\"User not found\")\n",
    "            return False\n",
    "\n",
    "        # Get user data\n",
    "        user_data = es_client.get(index=index_name, id=email)[\"_source\"]\n",
    "\n",
    "        # Check if password matches\n",
    "        # NOTE: In production, you should use proper password hashing and verification\n",
    "        if user_data[\"password\"] == password:\n",
    "            print(\"Login successful\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Invalid password\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during login: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "success = login_user(\"test@exgample.com\", \"hashed_password\", es)\n",
    "print(f\"Login successful: {success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User not found\n",
      "Should succeed: False\n",
      "User not found\n",
      "Should fail: False\n",
      "User not found\n",
      "Should fail: False\n"
     ]
    }
   ],
   "source": [
    "# Test with correct credentials\n",
    "success = login_user(\"test@example.com\", \"hashed_password\", es)\n",
    "print(f\"Should succeed: {success}\")\n",
    "\n",
    "# Test with wrong password\n",
    "success = login_user(\"test@example.com\", \"wrong_password\", es)\n",
    "print(f\"Should fail: {success}\")\n",
    "\n",
    "# Test with non-existent user\n",
    "success = login_user(\"nonexistent@example.com\", \"any_password\", es)\n",
    "print(f\"Should fail: {success}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed feedback from test@example.com at 2024-03-20T12:00:00\n",
      "Feedback indexing successful: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>input_description</th>\n",
       "      <th>input_image</th>\n",
       "      <th>recipe_ids</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test@example.com</td>\n",
       "      <td>I want a vegetarian pasta dish</td>\n",
       "      <td>None</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great recommendations!</td>\n",
       "      <td>2024-03-20T12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              email               input_description input_image recipe_ids  \\\n",
       "0  test@example.com  I want a vegetarian pasta dish        None  [1, 2, 3]   \n",
       "\n",
       "   rating                 comment           created_at  \n",
       "0       5  Great recommendations!  2024-03-20T12:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def index_feedback(\n",
    "    feedback: Feedback, es_client: Elasticsearch, index_name: str = \"feedback\"\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Index a Feedback model instance into Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        feedback: Feedback model instance\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index (default: \"feedback\")\n",
    "\n",
    "    Returns:\n",
    "        bool: True if feedback was indexed successfully, False if error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert Feedback model to dictionary\n",
    "        doc = feedback.model_dump()\n",
    "\n",
    "        # Generate a unique ID (you might want to use a different strategy)\n",
    "        doc_id = f\"{feedback.email}_{feedback.created_at}\"\n",
    "\n",
    "        # Index the document\n",
    "        es_client.index(index=index_name, id=doc_id, document=doc)\n",
    "        print(\n",
    "            f\"Successfully indexed feedback from {feedback.email} at {feedback.created_at}\"\n",
    "        )\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing feedback: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "sample_feedback = Feedback(\n",
    "    email=\"test@example.com\",\n",
    "    input_description=\"I want a vegetarian pasta dish\",\n",
    "    recipe_ids=[1, 2, 3],\n",
    "    rating=5,\n",
    "    comment=\"Great recommendations!\",\n",
    "    created_at=\"2024-03-20T12:00:00\",\n",
    ")\n",
    "\n",
    "# Index the sample feedback\n",
    "success = index_feedback(sample_feedback, es)\n",
    "print(f\"Feedback indexing successful: {success}\")\n",
    "\n",
    "# Verify it was indexed (optional)\n",
    "if success:\n",
    "    result = es.get(\n",
    "        index=\"feedback\", id=f\"{sample_feedback.email}_{sample_feedback.created_at}\"\n",
    "    )\n",
    "    display(pd.DataFrame([result[\"_source\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user data and embeddings functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing imports and models ...\n",
    "\n",
    "\n",
    "def get_user_profile(\n",
    "    email: str, es_client=es, index_name: str = \"users\"\n",
    ") -> Optional[User]:\n",
    "    \"\"\"\n",
    "    Retrieve a user profile from Elasticsearch by email and convert to User model\n",
    "\n",
    "    Args:\n",
    "        email: User's email address\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index (default: \"users\")\n",
    "\n",
    "    Returns:\n",
    "        Optional[User]: User model instance if found, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get user data by email (used as document ID)\n",
    "        result = es_client.get(index=index_name, id=email)\n",
    "\n",
    "        # Convert Elasticsearch document to User model\n",
    "        user_data = result[\"_source\"]\n",
    "        return User(**user_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving user profile: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "a = get_user_profile(\"test@exgample.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated embedding for user test@exgample.com\n"
     ]
    }
   ],
   "source": [
    "def update_user_embedding(\n",
    "    email: str,\n",
    "    embedding: List[float],\n",
    "    es_client: Elasticsearch,\n",
    "    index_name: str = \"users\",\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Update a user's embedding in Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        email: User's email address (used as document ID)\n",
    "        embedding: List of floats representing the user's new embedding\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index\n",
    "\n",
    "    Returns:\n",
    "        bool: True if update was successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if user exists\n",
    "        if not es_client.exists(index=index_name, id=email):\n",
    "            print(f\"User {email} not found\")\n",
    "            return False\n",
    "\n",
    "        # Update only the embedding field\n",
    "        update_doc = {\"doc\": {\"embedding\": embedding}}\n",
    "\n",
    "        es_client.update(index=index_name, id=email, body=update_doc)\n",
    "        print(f\"Successfully updated embedding for user {email}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating user embedding: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "new_embedding = [0.1] * 768  # Replace with actual embedding values\n",
    "success = update_user_embedding(\"test@exgample.com\", new_embedding, es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "userembedding = torch.tensor(a.embedding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_review(\n",
    "    email: str,\n",
    "    review: Review,  # Changed from review_text: str\n",
    "    es_client: Elasticsearch = es,\n",
    "    index_name: str = \"user_reviews\",\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Save a user review to Elasticsearch. If the user already has reviews, append to their list.\n",
    "    If not, create a new document for the user.\n",
    "\n",
    "    Args:\n",
    "        email: User's email address\n",
    "        review: Review object containing content and creation date\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index (default: \"user_reviews\")\n",
    "\n",
    "    Returns:\n",
    "        bool: True if review was saved successfully, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if user already has reviews\n",
    "        if es_client.exists(index=index_name, id=email):\n",
    "            # Get existing reviews\n",
    "            result = es_client.get(index=index_name, id=email)\n",
    "            user_reviews = result[\"_source\"][\"reviews\"]\n",
    "\n",
    "            # Append new review\n",
    "            user_reviews.append(review.model_dump())\n",
    "\n",
    "            # Update document\n",
    "            update_doc = {\"doc\": {\"reviews\": user_reviews}}\n",
    "            es_client.update(index=index_name, id=email, body=update_doc)\n",
    "        else:\n",
    "            # Create new UserReview document\n",
    "            user_review = UserReview(email=email, reviews=[review])\n",
    "            # Index new document\n",
    "            es_client.index(\n",
    "                index=index_name, id=email, document=user_review.model_dump()\n",
    "            )\n",
    "\n",
    "        print(f\"Successfully saved review for user {email}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving review: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-12-26 09:16:18.184582'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method-wrapper '__str__' of datetime.datetime object at 0x7f9924094de0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().__str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved review for user test.user@example.com\n",
      "First review saved: True\n",
      "\n",
      "After first review:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test.user@example.com</td>\n",
       "      <td>[{'created_at': '2024-12-26T09:08:58.065329', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   email                                            reviews\n",
       "0  test.user@example.com  [{'created_at': '2024-12-26T09:08:58.065329', ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved review for user test.user@example.com\n",
      "\n",
      "Second review saved: True\n",
      "\n",
      "After second review:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test.user@example.com</td>\n",
       "      <td>[{'created_at': '2024-12-26T09:08:58.065329', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   email                                            reviews\n",
       "0  test.user@example.com  [{'created_at': '2024-12-26T09:08:58.065329', ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving review: 1 validation error for UserReview\n",
      "email\n",
      "  value is not a valid email address: An email address must have an @-sign. [type=value_error, input_value='not-an-email', input_type=str]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from models import Review\n",
    "\n",
    "# Test saving a new review for a user\n",
    "test_email = \"test.user@example.com\"\n",
    "test_review = Review(content=\"This is my first review!\", created_at=str(datetime.now()))\n",
    "\n",
    "# First review - should create new document\n",
    "success = save_review(test_email, test_review)\n",
    "print(f\"First review saved: {success}\")\n",
    "\n",
    "# Verify the review was saved\n",
    "result = es.get(index=\"user_reviews\", id=test_email)\n",
    "print(\"\\nAfter first review:\")\n",
    "display(pd.DataFrame([result[\"_source\"]]))\n",
    "\n",
    "# Add a second review - should update existing document\n",
    "second_review = Review(\n",
    "    content=\"This is my second review!\", created_at=str(datetime.now())\n",
    ")\n",
    "success = save_review(test_email, second_review)\n",
    "print(f\"\\nSecond review saved: {success}\")\n",
    "\n",
    "# Verify both reviews are present\n",
    "result = es.get(index=\"user_reviews\", id=test_email)\n",
    "print(\"\\nAfter second review:\")\n",
    "display(pd.DataFrame([result[\"_source\"]]))\n",
    "\n",
    "# Test with invalid email (optional error case)\n",
    "try:\n",
    "    invalid_email = \"not-an-email\"\n",
    "    invalid_review = Review(content=\"This should fail\", created_at=str(datetime.now()))\n",
    "    save_review(invalid_email, invalid_review)\n",
    "except Exception as e:\n",
    "    print(f\"\\nExpected error with invalid email: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reviews for review_test@example.com:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-20T10:00:00</td>\n",
       "      <td>This is my first test review!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-20T11:00:00</td>\n",
       "      <td>This is my second test review!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                         content\n",
       "0  2024-03-20T10:00:00   This is my first test review!\n",
       "1  2024-03-20T11:00:00  This is my second test review!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No reviews found for user nonexistent@example.com\n",
      "\n",
      "Reviews for nonexistent@example.com:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_user_reviews(\n",
    "    email: str, es_client: Elasticsearch = es, index_name: str = \"user_reviews\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Get all reviews for a specific user from Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        email: User's email address\n",
    "        es_client: Elasticsearch client instance\n",
    "        index_name: Name of the Elasticsearch index (default: \"user_reviews\")\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains user's email and list of reviews, or empty reviews list if none found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if user has any reviews\n",
    "        if not es_client.exists(index=index_name, id=email):\n",
    "            print(f\"No reviews found for user {email}\")\n",
    "            return {\"email\": email, \"reviews\": []}\n",
    "\n",
    "        # Get user's reviews\n",
    "        result = es_client.get(index=index_name, id=email)\n",
    "        return result[\"_source\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving reviews: {e}\")\n",
    "        return {\"email\": email, \"reviews\": []}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with a user that has reviews\n",
    "    test_email = \"review_test@example.com\"\n",
    "    reviews = get_user_reviews(test_email)\n",
    "    print(f\"\\nReviews for {test_email}:\")\n",
    "    display(pd.DataFrame(reviews[\"reviews\"]))\n",
    "\n",
    "    # Test with a user that doesn't exist\n",
    "    nonexistent_email = \"nonexistent@example.com\"\n",
    "    reviews = get_user_reviews(nonexistent_email)\n",
    "    print(f\"\\nReviews for {nonexistent_email}:\")\n",
    "    display(pd.DataFrame(reviews[\"reviews\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 matching recipes\n",
      "\n",
      "First matching recipe:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Recipe(id=4640, title='afghani dhoog recipe - cucumber mint buttermilk/ chaas', ingredients=['cumin powder jeera', 'curd dahi yogurt', 'salt taste', 'ice cubes few', 'cucumber peeled chopped', 'mint leaves pudina'], instructions=['to begin making the afghani dhoog recipe - cucumber mint buttermilk/ chaas into the preethi zodiac blender tall jar add yogurt, mint leaves, cucumber, cumin, ice cubes and salt to taste.turn on the puree function and blent to make a smooth drink.\\xa0pour the\\xa0afghani dhoog into serving glass and serve chilled.serve this\\xa0afghani dhoog recipe - cucumber mint buttermilk/ chaas\\xa0with\\xa0lehsuni methi paneer\\xa0and\\xa0tawa paratha recipe - plain paratha\\xa0for lunch.'], prep_time=10, cook_time=0, cuisine='Afghan', course='Snack', diet='Vegetarian', image=None, url='http://www.archanaskitchen.com/doogh-afghani-yogurt-drink-recipe-with-mint', embedding=[-0.014779524877667427, -0.008534302935004234, -0.0744883343577385, -0.03696717694401741, -0.030413435772061348, -0.01963372901082039, 0.08197484910488129, 0.015984799712896347, -0.008281623013317585, -0.01813446544110775, 0.01583332195878029, -0.007788194343447685, -0.016843102872371674, 0.006552606821060181, 0.026714235544204712, -0.02012181654572487, -0.03553307056427002, 0.011504428461194038, 0.06585405766963959, 0.03866976499557495, -0.04172593355178833, -0.007925502955913544, 0.027118731290102005, 0.057973966002464294, -0.06075126677751541, 0.008262533694505692, 0.02240065671503544, 0.010038334876298904, -0.08305753767490387, 0.0010791192762553692, -0.029738983139395714, 0.03322988748550415, 0.03689977526664734, -0.029341133311390877, 0.04713655263185501, 0.0013164047850295901, 0.017050551250576973, 0.04868695139884949, -0.0007462422363460064, 0.07482201606035233, -0.04128829762339592, -0.04178332909941673, -0.004591610282659531, 0.032145749777555466, -0.05215885862708092, 0.024547701701521873, 0.0003281264507677406, -0.016482824459671974, -0.0014149616472423077, 0.01028403453528881, -0.034033991396427155, -0.027449285611510277, 0.006225483026355505, 0.030808990821242332, 0.007197970524430275, 0.07646862417459488, -0.059715043753385544, -0.03506838530302048, -0.011402706615626812, -0.003330836771056056, -0.010900831781327724, 0.007802964188158512, -0.019057227298617363, 0.01720677688717842, -0.005465943366289139, 0.02168939635157585, 0.02501191385090351, 0.02537526935338974, -0.026241818442940712, 0.017041921615600586, -0.008008584380149841, -0.032145604491233826, -0.010719357058405876, -0.030643515288829803, -0.003968001808971167, 0.08149557560682297, 0.031927090138196945, 0.02090531215071678, 0.019631650298833847, 0.018900882452726364, -0.025962162762880325, 0.03294452652335167, 0.002481662668287754, -0.01393476314842701, 0.027373304590582848, 0.03019040636718273, 0.003111406462267041, 0.031975507736206055, 0.10486476123332977, -0.0021440847776830196, -0.03809612989425659, 0.05817021429538727, -0.03303353488445282, 0.01906830072402954, 0.09751374274492264, 0.0031169161666184664, 0.04573899134993553, -0.04224057123064995, 0.003519179532304406, 0.049435727298259735, 0.03921263664960861, -0.005498971790075302, -0.021319949999451637, 0.008708756417036057, -0.006740393117070198, 0.04961543157696724, -0.06805188208818436, 0.030094852671027184, -0.05221300944685936, -0.027983298525214195, -0.04441571235656738, -0.017482345923781395, -0.03988342732191086, -0.014204869046807289, 0.030391687527298927, -0.0109019186347723, -0.01474388875067234, -0.036684587597846985, -0.027849717065691948, -0.006509716156870127, -0.05499544367194176, 0.06798148900270462, -0.0023338929750025272, -0.057038646191358566, 0.04064632207155228, -0.01173415593802929, 0.028720015659928322, -0.008922116830945015, -0.01338125392794609, -0.010457925498485565, -0.009750221855938435, -0.018087049946188927, 0.003503573825582862, -0.02798362821340561, -0.09435077756643295, 0.03177974745631218, -0.01328163780272007, 0.03847453370690346, -0.009908716194331646, -0.04975535720586777, 0.011346996761858463, -0.015496860258281231, -0.026503851637244225, 0.009049779735505581, -0.011207089759409428, -0.020495347678661346, 0.04155926778912544, -0.038504451513290405, -0.020040135830640793, -0.02245323359966278, 0.015423933044075966, -0.0592225044965744, -0.05628330260515213, 0.016208466142416, 0.004224106203764677, 0.04161514341831207, -0.0018602344207465649, 0.016641724854707718, 0.019911615177989006, -0.08072444051504135, -0.05448126420378685, 0.06269330531358719, -0.016327137127518654, -0.08080028742551804, 0.05789991840720177, -0.013287226669490337, 0.051792941987514496, 0.08415809273719788, -0.01799851655960083, -0.014323344454169273, 0.01708877459168434, 0.01794530265033245, -0.03696785867214203, 0.007128776051104069, -0.023902131244540215, -0.02428351528942585, -0.058494195342063904, -0.025534039363265038, -0.02776547148823738, -0.05911925435066223, -0.01388887595385313, -0.016887864097952843, 0.05694275349378586, 0.03288669511675835, 0.0637628510594368, 0.004016391932964325, 0.01611309126019478, 0.04778626188635826, -0.025609932839870453, -0.009042627178132534, -0.02271552011370659, -0.05271780863404274, -0.01379169337451458, 0.02019261009991169, 0.041400980204343796, 0.03149235621094704, 0.048953380435705185, -1.0027104508480988e-05, -0.0621567964553833, -0.02335124835371971, 0.035694293677806854, -0.030753960832953453, -0.031323470175266266, 0.005160273518413305, 0.015095654875040054, 0.009117921814322472, -0.043274469673633575, 0.002346714725717902, -0.030983682721853256, 0.03206786513328552, 0.00020058661175426096, -0.013377984054386616, -0.07177697122097015, -0.0077905673533678055, -0.009118509478867054, 0.04862673208117485, -0.009815528057515621, 0.047381386160850525, -0.011884085834026337, 0.00883410219103098, -0.0025181209202855825, 0.0024701147340238094, -0.08465119451284409, -0.0006560017354786396, 0.0026675511617213488, 0.001499330042861402, -0.0032392407301813364, -0.04573272168636322, 0.05016803741455078, -0.029600106179714203, -0.05216292664408684, 0.010660500265657902, 0.01776370219886303, 0.0208524651825428, 0.038899727165699005, 0.0340561605989933, 0.014596184715628624, -0.042015448212623596, 0.02607608214020729, -0.08720342069864273, 0.03940409794449806, -0.025509001687169075, 0.05063668638467789, -0.040517665445804596, -0.015665525570511818, -0.02651543915271759, 0.043826885521411896, -0.09082868695259094, 0.0836346447467804, 0.050085682421922684, -0.06649930775165558, 0.012884709052741528, 0.017145920544862747, -0.030239373445510864, 0.014906526543200016, 0.07540345937013626, -0.007828418165445328, 0.03231256827712059, -0.009684688411653042, 0.03906672075390816, -0.01681312546133995, -0.07502789795398712, -0.0376213900744915, 0.044627152383327484, -0.0174538716673851, -0.06650159507989883, 0.006492868531495333, 0.035057686269283295, -0.022636808454990387, 0.03746795654296875, 0.005522673949599266, -0.054953791201114655, 0.0856892541050911, -0.04622931033372879, 0.08842211216688156, 0.06248211860656738, -0.010557246394455433, 0.04706356301903725, 0.0057027325965464115, 0.025266412645578384, 0.011437742970883846, 0.006157334893941879, 0.03142628073692322, -0.0130084790289402, 0.03273121267557144, -0.07301288843154907, -0.012868570163846016, -0.012652290053665638, -0.022577514871954918, -0.007966738194227219, 0.0004078044439665973, -0.007901298813521862, -0.04673830792307854, -0.06050747260451317, 0.02932346984744072, -0.08945123106241226, -0.02173500508069992, 0.017545724287629128, -0.011783143505454063, 0.04190105199813843, 0.023394666612148285, -0.03413264453411102, -0.009640290401875973, 0.009321081452071667, 0.04492722824215889, 0.005032690707594156, 0.004877710249274969, -0.004659376107156277, 0.03871545568108559, 0.024032937362790108, 0.02996002323925495, -0.045024286955595016, -0.010304415598511696, -5.0592843763297424e-05, -0.029623670503497124, 0.04519324377179146, 0.0226917527616024, 0.019545774906873703, -0.002003089990466833, -0.046359430998563766, -0.033064600080251694, 0.06001702696084976, -0.0027036212850362062, 0.12247050553560257, 0.014035118743777275, -0.0816083550453186, -0.044517334550619125, -0.00975314062088728, 0.03719462454319, 0.008745801635086536, -0.013408834114670753, 0.003048650687560439, 0.04318302497267723, 0.0011819155188277364, 0.0032105809077620506, -0.019246192649006844, -0.004275607410818338, 0.04650847613811493, -0.037986792623996735, 0.04730033874511719, 0.05539756268262863, 0.020670145750045776, -0.03213905170559883, 0.019496271386742592, -0.019364643841981888, -0.0607052743434906, -0.013230583630502224, 0.02109339088201523, 0.034667450934648514, -0.016529686748981476, -0.07981480658054352, 0.02010229229927063, -0.007736530154943466, 0.016384249553084373, 0.024324120953679085, -0.04076109081506729, 0.004627017304301262, -0.00570656917989254, 0.06868553161621094, -0.030825115740299225, 0.04285159707069397, -0.02582295797765255, -0.01887292042374611, -0.008958401158452034, 0.025707285851240158, 0.0039334907196462154, -0.07969117164611816, -0.03762388601899147, -0.010526719503104687, 0.004203957039862871, -0.059364356100559235, -0.03148764744400978, -0.020843561738729477, -0.02136320434510708, 0.0022125213872641325, -0.004646968096494675, 0.022115854546427727, 0.007824053056538105, 0.0008404820109717548, 0.0011589963687583804, 0.017166098579764366, -0.018251268193125725, 0.011926324106752872, -0.007421332411468029, -0.057431191205978394, -0.04927472025156021, 0.016234029084444046, 0.07387030124664307, 0.013418619520962238, 0.04587740823626518, -0.012181555852293968, 0.06720584630966187, 0.027278613299131393, -0.0430096872150898, 0.0025610236916691065, 0.06289391964673996, -0.027263931930065155, -0.049644824117422104, 0.03244694322347641, 0.039577849209308624, 0.005597454961389303, -0.003449881449341774, 0.005683821626007557, -0.017283953726291656, -0.015337757766246796, 0.010192274115979671, -0.01512074749916792, -0.0022331494837999344, 0.0032625338062644005, 0.0023908941075205803, -0.00881549995392561, -0.006222530733793974, -0.0320703387260437, -0.05956225097179413, -0.03776109963655472, 0.0307932049036026, 0.006492285989224911, 0.02249661646783352, -0.049546197056770325, -0.052047740668058395, -0.00698270695284009, -0.0029995632357895374, 0.007094991859048605, -0.01455655787140131, 0.025336630642414093, -0.06909818947315216, -0.016742710024118423, 0.017999373376369476, -0.04992785304784775, 0.011129762977361679, 0.017564285546541214, -0.01073397882282734, 0.05703055113554001, -0.04110299050807953, -0.006380065344274044, -0.024656599387526512, 0.037325479090213776, 0.05747868865728378, 0.032867200672626495, 0.009920025244355202, -0.009298758581280708, -0.003543368773534894, 0.07653111219406128, 0.02492820844054222, 0.0007187122828327119, 0.009912192821502686, -0.022115660831332207, 0.0027190211694687605, 0.013047974556684494, -0.02373425103724003, 0.02130625769495964, -0.014035377651453018, 0.07607309520244598, 0.01636197417974472, -0.03357658162713051, 0.06182844564318657, -0.0062927850522100925, -0.020149966701865196, -0.026189815253019333, 0.03298835828900337, 0.011047678999602795, 0.05010893568396568, 0.05791165307164192, -0.005108036566525698, -0.020192811265587807, 0.004291648976504803, -0.006786856800317764, -0.03042636066675186, 0.04501703381538391, 0.058239955455064774, -0.021396100521087646, 0.12223094701766968, -0.01109117828309536, -0.05612979829311371, 0.0038873315788805485, 0.028096964582800865, 0.005167412105947733, 0.0167305376380682, -0.05437445640563965, -0.0001513417810201645, 0.010675723664462566, -0.033910855650901794, -0.02081899344921112, 0.04318012297153473, -0.018768612295389175, 0.03567597270011902, -0.0014771604910492897, -0.01592451147735119, 0.04207498952746391, 0.008523060008883476, 0.06960851699113846, -0.04470674693584442, -0.005145618692040443, -0.00507514551281929, 0.0022437640000134706, -0.018063604831695557, -0.04257076233625412, -0.0439218208193779, -0.01758602447807789, -0.0011757612228393555, -0.049626778811216354, -0.08393996208906174, 0.045835819095373154, 0.020202258601784706, 0.033805299550294876, 0.04020637646317482, -0.025537598878145218, 0.034980013966560364, 0.0014934609644114971, 0.04184399172663689, -0.013820306397974491, -0.053875334560871124, 0.000555604521650821, 0.05443502962589264, -0.005856855772435665, -0.009098084643483162, -0.03772802650928497, -0.0241149440407753, -0.002640858991071582, -0.01996535062789917, 0.03285352140665054, -0.004018285311758518, 0.02690376713871956, -0.04499073699116707, -0.046899616718292236, -0.006052631419152021, -0.018641512840986252, -0.09141948074102402, -0.012320543639361858, -0.033071573823690414, 0.0036264024674892426, 0.023262372240424156, 0.06864625960588455, 0.011673668399453163, 0.016135433688759804, -0.02266628108918667, 0.004614103119820356, 0.04236028343439102, -0.012749707326292992, 0.05443623661994934, -0.025363586843013763, 0.043669939041137695, -0.03409756347537041, -0.008773434907197952, -0.04492269828915596, 0.010701384395360947, -0.015335718169808388, -0.008273795247077942, 0.05486782640218735, -0.005085407756268978, -0.00391991063952446, -0.02259126305580139, 0.019459756091237068, -0.08355149626731873, -0.08422322571277618, -0.012074701488018036, -0.04750276356935501, 0.06897815316915512, -0.07523495703935623, 0.016397997736930847, -0.003456216538324952, -0.040217798203229904, -0.010386806912720203, 0.012848722748458385, -0.04026399925351143, 0.027521345764398575, 0.0534077025949955, -0.04124409705400467, 0.010735182091593742, -0.07227066159248352, -0.028172418475151062, 0.02246900089085102, -0.019396692514419556, -0.0696713998913765, -0.01720360293984413, -0.00792324636131525, 0.003734754165634513, -0.025199828669428825, -0.07865819334983826, -0.013398408889770508, -0.0009251290466636419, -0.012855460867285728, -0.02114463783800602, 0.017543558031320572, -0.04012593999505043, 0.039096180349588394, -0.0022984612733125687, 0.050036948174238205, 0.014468091540038586, -0.02001173235476017, -0.009939653798937798, -0.04530579224228859, -0.0335063636302948, -0.06620731949806213, 0.036656614392995834, 0.0013117885682731867, -0.0006781060365028679, 0.02307547628879547, -0.0046250890009105206, 0.03166041895747185, -0.014834138564765453, 0.006810336373746395, 0.0011044261045753956, -0.07586156576871872, 0.022962508723139763, -0.016018813475966454, 0.017178524285554886, 0.025721371173858643, -0.029356542974710464, -0.006491036619991064, 0.039528824388980865, 0.015901045873761177, -0.014374432153999805, 0.0315667949616909, -0.03676162660121918, 0.006050976924598217, -0.007574205752462149, 0.016962047666311264, 0.006638760212808847, -0.004772444721311331, -0.0017840927466750145, -0.021354803815484047, -0.04880538210272789, 0.004915760830044746, -0.012947918847203255, -0.017859352752566338, 0.025145182386040688, 0.018556583672761917, 0.03629531338810921, -0.04181806743144989, -0.0018685702234506607, -0.02514573745429516, -0.021932173520326614, 0.07832512259483337, -0.021614039316773415, 0.018036819994449615, 0.03662208095192909, -0.02932373620569706, -0.026648376137018204, 0.05661933496594429, -0.007076366804540157, 0.00466779712587595, 0.014847678132355213, 0.016428304836153984, -0.0011879149824380875, 0.03689604252576828, -0.006636120844632387, 0.01795523427426815, 0.013292914256453514, -0.03338286653161049, -0.01907186582684517, -0.03296659514307976, -0.008834801614284515, 0.049045711755752563, 0.02938520535826683, 0.025918181985616684, -0.029962794855237007, 0.05916547402739525, 0.00333751761354506, 0.003670014441013336, -0.05701914057135582, -0.03802761435508728, -0.0013176072388887405, 0.031169241294264793, 0.032113753259181976, 0.03829343616962433, 0.03385839983820915, -0.047534458339214325, 0.030906502157449722, -0.027423758059740067, 0.09335879236459732, -0.0023567224852740765, 0.03026484325528145, 0.009245269931852818, 0.010959425009787083, -0.003120245411992073, 0.007338178809732199, 0.0697244182229042, -0.05593022331595421, -0.03980136662721634, 0.03954164311289787, 0.011615653522312641, -0.03753882274031639, -0.012394117191433907, 0.03492520749568939, -0.009483110159635544, 0.004171376582235098, 0.005464345216751099, -0.02095068246126175, -0.08200476318597794, 0.05108770355582237, -0.00011169696517754346, 0.06647373735904694, 0.0024348159786313772, -0.021995041519403458, 0.023351969197392464, 0.050157900899648666, 0.03824956715106964, -0.021585647016763687, 0.0038514146581292152, -0.022288594394922256, -0.030532004311680794, -0.023744948208332062, -0.023534361273050308, -0.011283989995718002, 0.022897658869624138, 0.0680437907576561, -0.047891225665807724, -0.04848941043019295, -0.011600549332797527, 0.01192282885313034, -0.02016051486134529, 0.011271203868091106, -0.010733801871538162, 0.011137216351926327, 0.0076379175297915936, 0.07122982293367386, 0.0642208680510521, 0.04294135421514511, 0.05168137699365616, -0.010704046115279198, 0.01827939972281456, -0.037859443575143814, -0.0018293434986844659, 0.04465195909142494, -0.05630842596292496, -0.017780866473913193, -0.02688799798488617, 0.0489576980471611, 0.01329307071864605, -0.04731889069080353, 0.001865855767391622, -0.02837539277970791, 0.012960333377122879, -0.056772343814373016, -0.039350725710392, 0.0023618959821760654, 0.009105113334953785, 0.08790357410907745, 0.032154034823179245, 0.03181106969714165, 0.04788678511977196, -0.06179384887218475, 0.05865183100104332, -0.033740099519491196, 0.06984571367502213, -0.010635845363140106, -0.03403361886739731, 0.020988473668694496, 0.01933903619647026, -0.05298149585723877, -0.019197383895516396, 0.059440359473228455, 0.03415631130337715, -0.005886388942599297, 0.04987958073616028, -0.03434411436319351, 0.01753615029156208, -0.018377982079982758, -0.024770332500338554, 0.022250153124332428, -0.03669804334640503, 0.007964902557432652, 0.020290357992053032, 0.014086544513702393, -0.03939575329422951, 0.014959899708628654, -0.017667872831225395])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>course</th>\n",
       "      <th>diet</th>\n",
       "      <th>embedding</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4640</td>\n",
       "      <td>afghani dhoog recipe - cucumber mint buttermil...</td>\n",
       "      <td>[cumin powder jeera, curd dahi yogurt, salt ta...</td>\n",
       "      <td>[to begin making the afghani dhoog recipe - cu...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghan</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[-0.014779524877667427, -0.008534302935004234,...</td>\n",
       "      <td>http://www.archanaskitchen.com/doogh-afghani-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5978</td>\n",
       "      <td>malida recipe (healthy whole wheat afghan sweet)</td>\n",
       "      <td>[cardamom powder elaichi, dates pitted finely ...</td>\n",
       "      <td>[to begin making the malida recipe, tear the r...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Afghan</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[-0.01772255077958107, -0.019701037555933, -0....</td>\n",
       "      <td>https://www.archanaskitchen.com/malida-recipe-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7092</td>\n",
       "      <td>moroccan spiced millet and lentil salad recipe</td>\n",
       "      <td>[tomato chopped, extra virgin olive oil, onion...</td>\n",
       "      <td>[to begin making the moroccan spiced millet an...</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>African</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[-0.06342744827270508, -0.01326711568981409, -...</td>\n",
       "      <td>https://www.archanaskitchen.com/moroccan-spice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2096</td>\n",
       "      <td>marrakesh vegetable curry recipe</td>\n",
       "      <td>[raisins few, badam almond few, onion chopped,...</td>\n",
       "      <td>[to begin making marrakesh vegetable curry rec...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>African</td>\n",
       "      <td>Main Course</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[-0.0607549324631691, 0.0676780492067337, -0.0...</td>\n",
       "      <td>http://www.archanaskitchen.com/marrakesh-veget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3055</td>\n",
       "      <td>scrambled tofu noodles recipe</td>\n",
       "      <td>[onion, mixed vegetables carrot, chilli vinega...</td>\n",
       "      <td>[to begin making the scrambled tofu noodles re...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>[-0.00255050347186625, -0.04626411944627762, -...</td>\n",
       "      <td>http://www.archanaskitchen.com/scrambled-tofu-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title  \\\n",
       "0  4640  afghani dhoog recipe - cucumber mint buttermil...   \n",
       "1  5978   malida recipe (healthy whole wheat afghan sweet)   \n",
       "2  7092     moroccan spiced millet and lentil salad recipe   \n",
       "3  2096                   marrakesh vegetable curry recipe   \n",
       "4  3055                      scrambled tofu noodles recipe   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [cumin powder jeera, curd dahi yogurt, salt ta...   \n",
       "1  [cardamom powder elaichi, dates pitted finely ...   \n",
       "2  [tomato chopped, extra virgin olive oil, onion...   \n",
       "3  [raisins few, badam almond few, onion chopped,...   \n",
       "4  [onion, mixed vegetables carrot, chilli vinega...   \n",
       "\n",
       "                                        instructions  prep_time  cook_time  \\\n",
       "0  [to begin making the afghani dhoog recipe - cu...         10          0   \n",
       "1  [to begin making the malida recipe, tear the r...         20         20   \n",
       "2  [to begin making the moroccan spiced millet an...         10         20   \n",
       "3  [to begin making marrakesh vegetable curry rec...         15         20   \n",
       "4  [to begin making the scrambled tofu noodles re...         10         10   \n",
       "\n",
       "   cuisine       course                     diet  \\\n",
       "0   Afghan        Snack               Vegetarian   \n",
       "1   Afghan        Snack               Vegetarian   \n",
       "2  African       Dinner               Vegetarian   \n",
       "3  African  Main Course               Vegetarian   \n",
       "4    Asian       Dinner  High Protein Vegetarian   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.014779524877667427, -0.008534302935004234,...   \n",
       "1  [-0.01772255077958107, -0.019701037555933, -0....   \n",
       "2  [-0.06342744827270508, -0.01326711568981409, -...   \n",
       "3  [-0.0607549324631691, 0.0676780492067337, -0.0...   \n",
       "4  [-0.00255050347186625, -0.04626411944627762, -...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.archanaskitchen.com/doogh-afghani-y...  \n",
       "1  https://www.archanaskitchen.com/malida-recipe-...  \n",
       "2  https://www.archanaskitchen.com/moroccan-spice...  \n",
       "3  http://www.archanaskitchen.com/marrakesh-veget...  \n",
       "4  http://www.archanaskitchen.com/scrambled-tofu-...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_recipes_elastic(es_client=es, **kwargs) -> Tuple[List[Recipe], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create and execute an Elasticsearch query based on filter parameters\n",
    "\n",
    "    Args:\n",
    "        es_client: Elasticsearch client instance\n",
    "        **kwargs: Filter parameters (prep_time, cook_time, cuisine, course, diet, ingredients)\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Recipe], pd.DataFrame]: Tuple containing:\n",
    "            - List of matching Recipe model instances\n",
    "            - DataFrame containing the same data\n",
    "    \"\"\"\n",
    "    # Start with a match_all query\n",
    "    query = {\"bool\": {\"must\": [], \"filter\": []}}\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        if key == \"Title\" or not value:\n",
    "            continue\n",
    "\n",
    "        if key in [\"prep_time\", \"cook_time\"]:\n",
    "            query[\"bool\"][\"filter\"].append({\"range\": {key.lower(): {\"lte\": value}}})\n",
    "        elif key in [\"cuisine\", \"course\", \"diet\"]:\n",
    "            if isinstance(value, list) and value:\n",
    "                query[\"bool\"][\"must\"].append({\"terms\": {key.lower(): value}})\n",
    "        elif key == \"Cleaned_Ingredients\" and value:\n",
    "            query[\"bool\"][\"must\"].append({\"terms\": {\"ingredients.keyword\": value}})\n",
    "\n",
    "    # Construct the full search body\n",
    "    search_body = {\"query\": query, \"size\": 100}\n",
    "\n",
    "    try:\n",
    "        # Execute the search\n",
    "        response = es_client.search(index=\"recipes\", body=search_body)\n",
    "\n",
    "        # Convert hits to Recipe models and collect data for DataFrame\n",
    "        recipes = []\n",
    "        df_data = []\n",
    "\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            source = hit[\"_source\"]\n",
    "            recipe = Recipe(\n",
    "                id=source[\"id\"],\n",
    "                title=source[\"title\"],\n",
    "                ingredients=source[\"ingredients\"],\n",
    "                instructions=source[\"instructions\"],\n",
    "                prep_time=source[\"prep_time\"],\n",
    "                cook_time=source[\"cook_time\"],\n",
    "                cuisine=source[\"cuisine\"],\n",
    "                course=source[\"course\"],\n",
    "                diet=source[\"diet\"],\n",
    "                image=source.get(\"image\"),\n",
    "                url=source.get(\"url\"),\n",
    "                embedding=source.get(\"embedding\"),\n",
    "            )\n",
    "            recipes.append(recipe)\n",
    "\n",
    "            # Add the same data to the DataFrame collection\n",
    "            df_data.append(\n",
    "                {\n",
    "                    \"id\": recipe.id,\n",
    "                    \"title\": recipe.title,\n",
    "                    \"ingredients\": recipe.ingredients,\n",
    "                    \"instructions\": recipe.instructions,\n",
    "                    \"prep_time\": recipe.prep_time,\n",
    "                    \"cook_time\": recipe.cook_time,\n",
    "                    \"cuisine\": recipe.cuisine,\n",
    "                    \"course\": recipe.course,\n",
    "                    \"diet\": recipe.diet,\n",
    "                    \"embedding\": recipe.embedding,\n",
    "                    \"url\": recipe.url,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(df_data)\n",
    "\n",
    "        return recipes, df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing Elasticsearch query: {e}\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "\n",
    "# Test the updated function\n",
    "test_recipes, test_df = filter_recipes_elastic(\n",
    "    # es,\n",
    "    prep_time=20,\n",
    "    cook_time=20,\n",
    "    # cuisine=[\"Afghan\"],\n",
    "    course=[\"Dinner\", \"Snack\", \"Main Course\"],\n",
    ")\n",
    "print(f\"Found {len(test_recipes)} matching recipes\")\n",
    "\n",
    "if test_recipes:\n",
    "    print(\"\\nFirst matching recipe:\")\n",
    "    display(test_recipes[0])\n",
    "    print(\"\\nDataFrame head:\")\n",
    "    display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df[\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(strings_list, api_url=\"http://localhost:8000/encode\"):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of strings (text or base64-encoded images)\n",
    "\n",
    "    Args:\n",
    "        strings_list (list): List of strings (text or base64-encoded images)\n",
    "        api_url (str): URL of the embedding API\n",
    "\n",
    "    Returns:\n",
    "        list: List of embeddings\n",
    "    \"\"\"\n",
    "    embeddings_list = []\n",
    "\n",
    "    for string in strings_list:\n",
    "        try:\n",
    "            response = requests.post(api_url, json={\"content\": string})\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "\n",
    "            if result[\"status\"] == \"success\":\n",
    "                embeddings_list.append(\n",
    "                    {\n",
    "                        \"input\": (\n",
    "                            string[:50] + \"...\" if len(string) > 50 else string\n",
    "                        ),  # Truncate long strings in log\n",
    "                        \"type\": result[\"type\"],\n",
    "                        \"embeddings\": result[\"embeddings\"],\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Error processing string: {result.get('message', 'Unknown error')}\"\n",
    "                )\n",
    "                embeddings_list.append(\n",
    "                    {\n",
    "                        \"input\": string[:50] + \"...\",\n",
    "                        \"type\": \"error\",\n",
    "                        \"error\": result.get(\"message\", \"Unknown error\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in API call: {str(e)}\")\n",
    "            embeddings_list.append(\n",
    "                {\"input\": string[:50] + \"...\", \"type\": \"error\", \"error\": str(e)}\n",
    "            )\n",
    "\n",
    "    return embeddings_list\n",
    "\n",
    "\n",
    "def compute_average_embedding(title_text=None, image=None):\n",
    "    embeddings = []\n",
    "    if title_text:\n",
    "        result = get_embeddings([title_text])[0]\n",
    "        if result.get(\"type\") != \"error\":\n",
    "            title_embedding = np.array(result[\"embeddings\"])\n",
    "            embeddings.append(title_embedding)\n",
    "\n",
    "    if image:\n",
    "        # Convert PIL Image to base64 if needed\n",
    "        if isinstance(image, Image.Image):\n",
    "            buffered = BytesIO()\n",
    "            image.save(buffered, format=\"PNG\")\n",
    "            img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "        else:\n",
    "            # Assume it's already base64 encoded\n",
    "            img_str = image\n",
    "\n",
    "        result = get_embeddings([img_str])[0]\n",
    "        if result.get(\"type\") != \"error\":\n",
    "            image_embedding = np.array(result[\"embeddings\"])\n",
    "            embeddings.append(image_embedding)\n",
    "\n",
    "    if len(embeddings) == 0:\n",
    "        raise ValueError(\"No valid embeddings could be generated from the input\")\n",
    "\n",
    "    # Ensure all embeddings have the same shape\n",
    "    embeddings = [emb.flatten() for emb in embeddings]\n",
    "\n",
    "    # Compute the average of all available embeddings\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "    return avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "embedding = compute_average_embedding(\"lentil soup\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_recipe(\n",
    "    avg_embedding, ids, top_n=5, min_similarity=0.7\n",
    ") -> tuple[List[Recipe], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Find recipes from a specific set of IDs with embedding similarity > min_similarity\n",
    "\n",
    "    Args:\n",
    "        avg_embedding: Query embedding vector\n",
    "        ids: List of recipe IDs to search within\n",
    "        top_n: Maximum number of results to return (default 5)\n",
    "        min_similarity: Minimum similarity threshold (default 0.7)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (List[Recipe], pd.DataFrame) containing similar recipes\n",
    "    \"\"\"\n",
    "    # Convert embedding to list if it's numpy array\n",
    "    if hasattr(avg_embedding, \"tolist\"):\n",
    "        avg_embedding = avg_embedding.tolist()\n",
    "\n",
    "    # Query that combines ID filtering with similarity scoring\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\"terms\": {\"id\": ids}},  # Filter by provided IDs\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                    \"params\": {\"query_vector\": avg_embedding},\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"min_score\": 1 + 0.4,  # Add 1 to adjust for the +1.0 in script\n",
    "        \"size\": top_n,\n",
    "        \"_source\": True,  # Get all fields\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Execute search\n",
    "        response = es.search(index=\"recipes\", body=query)\n",
    "\n",
    "        # Convert hits to Recipe models and collect data for DataFrame\n",
    "        recipes = []\n",
    "        df_data = []\n",
    "\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            source = hit[\"_source\"]\n",
    "            similarity = hit[\"_score\"] - 1.0  # Convert back to -1 to 1 range\n",
    "\n",
    "            # Create Recipe model\n",
    "            recipe = Recipe(\n",
    "                id=source[\"id\"],\n",
    "                title=source[\"title\"],\n",
    "                ingredients=source[\"ingredients\"],\n",
    "                instructions=source[\"instructions\"],\n",
    "                prep_time=source[\"prep_time\"],\n",
    "                cook_time=source[\"cook_time\"],\n",
    "                cuisine=source[\"cuisine\"],\n",
    "                course=source[\"course\"],\n",
    "                diet=source[\"diet\"],\n",
    "                image=source.get(\"image\"),\n",
    "                url=source.get(\"url\"),\n",
    "                embedding=source.get(\"embedding\"),\n",
    "            )\n",
    "            recipes.append(recipe)\n",
    "\n",
    "            # Add data for DataFrame\n",
    "            df_data.append(\n",
    "                {\n",
    "                    \"id\": recipe.id,\n",
    "                    \"title\": recipe.title,\n",
    "                    \"ingredients\": recipe.ingredients,\n",
    "                    \"instructions\": recipe.instructions,\n",
    "                    \"prep_time\": recipe.prep_time,\n",
    "                    \"cook_time\": recipe.cook_time,\n",
    "                    \"cuisine\": recipe.cuisine,\n",
    "                    \"course\": recipe.course,\n",
    "                    \"diet\": recipe.diet,\n",
    "                    \"embedding\": recipe.embedding,\n",
    "                    \"url\": recipe.url,\n",
    "                    \"similarity\": similarity,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(df_data)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding similar recipes: {e}\")\n",
    "        return [], pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>course</th>\n",
       "      <th>diet</th>\n",
       "      <th>embedding</th>\n",
       "      <th>url</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3747</td>\n",
       "      <td>asian carrot ginger lentil soup recipe</td>\n",
       "      <td>[carrot gajjar, onion, fresh red chilli, green...</td>\n",
       "      <td>[to begin making the asian carrot ginger lenti...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>[-0.07616453617811203, 0.03793567791581154, -0...</td>\n",
       "      <td>http://www.archanaskitchen.com/asian-carrot-gi...</td>\n",
       "      <td>0.675560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3284</td>\n",
       "      <td>chickpea soup recipe</td>\n",
       "      <td>[onion chopped, of chickpea chickpea chickpeas...</td>\n",
       "      <td>[काबुली चना सूप रेसिपी बनाने के लिए सबसे पहले ...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>North Indian Recipes</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>[-0.08105280995368958, -0.018381595611572266, ...</td>\n",
       "      <td>https://www.archanaskitchen.com/chickpea-soup-...</td>\n",
       "      <td>0.653313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6825</td>\n",
       "      <td>moroccan lentil stew recipe with raisins</td>\n",
       "      <td>[ginger grated, lukewarm water, sweet potato d...</td>\n",
       "      <td>[to start making moroccan lentil stew with rai...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>African</td>\n",
       "      <td>Main Course</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>[-0.06751316785812378, 0.0513836070895195, -0....</td>\n",
       "      <td>https://www.archanaskitchen.com/moroccan-lenti...</td>\n",
       "      <td>0.627930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4780</td>\n",
       "      <td>carrot soup recipe</td>\n",
       "      <td>[whole pepper crush make of vegetable stock, o...</td>\n",
       "      <td>[to make the carrot soup recipe, first heat th...</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Continental</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[-0.07973533868789673, 0.03646014630794525, -0...</td>\n",
       "      <td>http://www.archanaskitchen.com/carrot-soup-rec...</td>\n",
       "      <td>0.617958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1438</td>\n",
       "      <td>lentil sauce recipe - stewed coconut milk sauce</td>\n",
       "      <td>[fresh coconut grated, yellow moong dal split ...</td>\n",
       "      <td>[to begin making paruppu payasam, first heat g...</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>Kerala Recipes</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>[-0.04027669504284859, -0.013138574548065662, ...</td>\n",
       "      <td>http://www.archanaskitchen.com/paruppu-payasam...</td>\n",
       "      <td>0.610544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                            title  \\\n",
       "0  3747           asian carrot ginger lentil soup recipe   \n",
       "1  3284                             chickpea soup recipe   \n",
       "2  6825         moroccan lentil stew recipe with raisins   \n",
       "3  4780                               carrot soup recipe   \n",
       "4  1438  lentil sauce recipe - stewed coconut milk sauce   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [carrot gajjar, onion, fresh red chilli, green...   \n",
       "1  [onion chopped, of chickpea chickpea chickpeas...   \n",
       "2  [ginger grated, lukewarm water, sweet potato d...   \n",
       "3  [whole pepper crush make of vegetable stock, o...   \n",
       "4  [fresh coconut grated, yellow moong dal split ...   \n",
       "\n",
       "                                        instructions  prep_time  cook_time  \\\n",
       "0  [to begin making the asian carrot ginger lenti...         15         20   \n",
       "1  [काबुली चना सूप रेसिपी बनाने के लिए सबसे पहले ...         15         20   \n",
       "2  [to start making moroccan lentil stew with rai...         15         30   \n",
       "3  [to make the carrot soup recipe, first heat th...         10         15   \n",
       "4  [to begin making paruppu payasam, first heat g...         10         40   \n",
       "\n",
       "                cuisine       course                     diet  \\\n",
       "0                 Asian       Dinner  High Protein Vegetarian   \n",
       "1  North Indian Recipes       Dinner  High Protein Vegetarian   \n",
       "2               African  Main Course  High Protein Vegetarian   \n",
       "3           Continental       Dinner               Vegetarian   \n",
       "4        Kerala Recipes      Dessert               Vegetarian   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.07616453617811203, 0.03793567791581154, -0...   \n",
       "1  [-0.08105280995368958, -0.018381595611572266, ...   \n",
       "2  [-0.06751316785812378, 0.0513836070895195, -0....   \n",
       "3  [-0.07973533868789673, 0.03646014630794525, -0...   \n",
       "4  [-0.04027669504284859, -0.013138574548065662, ...   \n",
       "\n",
       "                                                 url  similarity  \n",
       "0  http://www.archanaskitchen.com/asian-carrot-gi...    0.675560  \n",
       "1  https://www.archanaskitchen.com/chickpea-soup-...    0.653313  \n",
       "2  https://www.archanaskitchen.com/moroccan-lenti...    0.627930  \n",
       "3  http://www.archanaskitchen.com/carrot-soup-rec...    0.617958  \n",
       "4  http://www.archanaskitchen.com/paruppu-payasam...    0.610544  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_recipe(embedding, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asfasdasf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backendEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
